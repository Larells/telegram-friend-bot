
import logging
import json
import os
import openai
from aiogram import Bot, Dispatcher, types, executor
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton
from gtts import gTTS
import tempfile
import speech_recognition as sr

# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
with open("config.json", "r") as f:
    config = json.load(f)

TELEGRAM_TOKEN = config["telegram_token"]
OPENAI_API_KEY = config["openai_api_key"]
ADMIN_USERNAME = config["admin_username"]

openai.api_key = OPENAI_API_KEY
bot = Bot(token=TELEGRAM_TOKEN)
dp = Dispatcher(bot)

logging.basicConfig(level=logging.INFO)

# –ü–∞–º—è—Ç—å —á–∞—Ç–∞
chat_memory = {}

# –ö–Ω–æ–ø–∫–∏
main_kb = ReplyKeyboardMarkup(resize_keyboard=True)
main_kb.add(KeyboardButton("üí¨ –ü–æ–≥–æ–≤–æ—Ä–∏ —Å–æ –º–Ω–æ–π"), KeyboardButton("üòÇ –ê–Ω–µ–∫–¥–æ—Ç"))
main_kb.add(KeyboardButton("üé® –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"), KeyboardButton("üó£Ô∏è –û—Ç–ø—Ä–∞–≤—å –≥–æ–ª–æ—Å"))

@dp.message_handler(commands=["start"])
async def start(msg: types.Message):
    await msg.answer("–ü—Ä–∏–≤–µ—Ç! –Ø —Ç–≤–æ–π –±–æ—Ç-–¥—Ä—É–≥ ü§ó", reply_markup=main_kb)

@dp.message_handler(lambda message: message.text == "üí¨ –ü–æ–≥–æ–≤–æ—Ä–∏ —Å–æ –º–Ω–æ–π")
async def talk(msg: types.Message):
    await msg.answer("–ù–∞–ø–∏—à–∏, –æ —á—ë–º —Ö–æ—á–µ—à—å –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å?")

@dp.message_handler(lambda message: message.text == "üòÇ –ê–Ω–µ–∫–¥–æ—Ç")
async def joke(msg: types.Message):
    with open("jokes.txt", "r", encoding="utf-8") as f:
        jokes = f.readlines()
    from random import choice
    await msg.answer(choice(jokes))

@dp.message_handler(lambda message: message.text == "üé® –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
async def generate_image(msg: types.Message):
    await msg.answer("–ß—Ç–æ –Ω–∞—Ä–∏—Å–æ–≤–∞—Ç—å? –ù–∞–ø–∏—à–∏ –æ–ø–∏—Å–∞–Ω–∏–µ.")

@dp.message_handler(lambda message: message.text == "üó£Ô∏è –û—Ç–ø—Ä–∞–≤—å –≥–æ–ª–æ—Å")
async def send_voice(msg: types.Message):
    text = "–ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ –≥–æ–ª–æ—Å –æ—Ç –±–æ—Ç–∞-–¥—Ä—É–≥–∞."
    tts = gTTS(text)
    with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as fp:
        tts.save(fp.name)
        await msg.answer_voice(types.InputFile(fp.name))
    os.unlink(fp.name)

@dp.message_handler(content_types=types.ContentType.VOICE)
async def handle_voice(msg: types.Message):
    file_info = await bot.get_file(msg.voice.file_id)
    file_path = file_info.file_path
    file = await bot.download_file(file_path)
    with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as f:
        f.write(file.read())
        f.flush()
        try:
            from pydub import AudioSegment
            sound = AudioSegment.from_ogg(f.name)
            wav_path = f.name + ".wav"
            sound.export(wav_path, format="wav")

            r = sr.Recognizer()
            with sr.AudioFile(wav_path) as source:
                audio = r.record(source)
                text = r.recognize_google(audio, language="ru-RU")
                await msg.answer(f"–¢—ã —Å–∫–∞–∑–∞–ª: {text}")
                os.remove(wav_path)
        except Exception as e:
            await msg.answer(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
        finally:
            os.remove(f.name)

@dp.message_handler()
async def gpt_chat(msg: types.Message):
    user_id = str(msg.from_user.id)
    if user_id not in chat_memory:
        chat_memory[user_id] = []
    chat_memory[user_id].append({"role": "user", "content": msg.text})

    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=chat_memory[user_id][-10:]
    )
    answer = response.choices[0].message["content"]
    chat_memory[user_id].append({"role": "assistant", "content": answer})
    await msg.answer(answer)

if __name__ == "__main__":
    executor.start_polling(dp, skip_updates=True)
